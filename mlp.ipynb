{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardobizerra/custom-mlp/blob/main/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WECeh57QhL9O"
      },
      "source": [
        "## IF867 - Introdução à Aprendizagem Profunda\n",
        "### 1ª atividade prática\n",
        "\n",
        "Discente(s): Ricardo Bizerra de Lima Filho (rblf)\n",
        "\n",
        "Período: 2024.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRkbCshWhfya"
      },
      "source": [
        "## Instruções e Requisitos\n",
        "- Objetivo: Implementar e treinar um Multilayer Perceptron (MLP), inteiramente em [NumPy](https://numpy.org/doc/stable/) ou [Numba](https://numba.readthedocs.io/en/stable/index.html), sem o uso de bibliotecas de aprendizado profundo.\n",
        "- A atividade pode ser feita em dupla.\n",
        "\n",
        "### Tarefas\n",
        "\n",
        "__Implementação (50%):__\n",
        "\n",
        "- Construa um MLP com uma camada de entrada, pelo menos duas camadas ocultas e uma camada de saída.\n",
        "- Implemente pelo menos duas funções de ativação diferentes para as camadas ocultas; use Sigmoid e Linear para a camada de saída.\n",
        "- Implemente forward e backpropagation.\n",
        "- Implemente um otimizador de sua escolha, adequado ao problema abordado.\n",
        "- Implemente as funções de treinamento e avaliação.\n",
        "\n",
        "__Aplicação (30%):__\n",
        "\n",
        "  Teste se os seus modelos estão funcionando bem com as seguintes tarefas:\n",
        "  - Regressão\n",
        "  - Classificação binária\n",
        "\n",
        "__Experimentação (20%):__\n",
        "\n",
        "  Teste os seus modelos com variações na arquitetura, no pré-processamento, etc. Escolha pelo menos uma das seguintes opções:\n",
        "  - Variações na inicialização de pesos\n",
        "  - Variações na arquitetura\n",
        "  - Implementação de técnicas de regularização\n",
        "  - Visualização das ativações e gradientes\n",
        "\n",
        "***Bônus:*** Implemente o MLP utilizando uma biblioteca de machine learning (ex.: [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/?hl=pt-br), [tinygrad](https://docs.tinygrad.org/), [Jax](https://jax.readthedocs.io/en/latest/quickstart.html)) e teste-o em uma das aplicações e em um dos experimentos propostos. O bônus pode substituir um dos desafios de aplicação ou experimentos feitos em NumPy, ou simplesmente somar pontos para a pontuação geral.\n",
        "\n",
        "### Datasets recomendados:\n",
        "Aqui estão alguns datasets recomendados, mas fica a cargo do aluno escolher os datasets que utilizará na atividade, podendo escolher um dataset não listado abaixo.\n",
        "- Classificação\n",
        "\n",
        "  - [Iris](https://archive.ics.uci.edu/dataset/53/iris)\n",
        "  - [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
        "  - [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)\n",
        "\n",
        "- Regressão\n",
        "\n",
        "  - [Air Quality](https://archive.ics.uci.edu/dataset/360/air+quality)\n",
        "  - [Student Performance](https://archive.ics.uci.edu/dataset/320/student+performance)\n",
        "  - [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
        "\n",
        "### Requisitos para Entrega\n",
        "\n",
        "Um notebook Jupyter (de preferência, o link do colab) ou script Python contendo:\n",
        "\n",
        "- Código: Implementação completa da MLP.\n",
        "- Gráficos e Análises: Gráficos da curva de perda, ativações, gradientes e insights do treinamento, resultantes dos experimentos com parada antecipada e diferentes técnicas de regularização.\n",
        "- Relatório: Um breve relatório detalhando o impacto de várias configurações de hiperparâmetros(ex.: inicialização de pesos, número de camadas ocultas e neurônios) e métodos de regularização no desempenho do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__PXHTW_wYR",
        "outputId": "055b5559-2b16-49c2-a09e-d69a7496cccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bdV-R1nvADsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "lFH3riTWq-J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset para Classificação Binária: Breast Cancer Wisconsin\n",
        "\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "X_classification = breast_cancer_wisconsin_diagnostic.data.features.values\n",
        "X_classification = X_classification.T\n",
        "\n",
        "y_classification = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "y_classification = (y_classification[\"Diagnosis\"] == \"B\").astype(int)\n",
        "y_classification = y_classification.values\n",
        "y_classification = y_classification.reshape(1, -1)"
      ],
      "metadata": {
        "id": "YWK3-qtO_zUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset para Regressão: Student Performance\n",
        "\n",
        "student_performance = fetch_ucirepo(id=320)\n",
        "\n",
        "X_regression = student_performance.data.features.values.T\n",
        "y_regression = student_performance.data.targets.values"
      ],
      "metadata": {
        "id": "czVfXbiXcUSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções de ativação\n",
        "\n",
        "def activation_sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def activation_tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def activation_relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def activation_linear(x):\n",
        "  return x\n",
        "\n",
        "activation_functions = {\n",
        "    \"sigmoid\": activation_sigmoid,\n",
        "    \"tanh\": activation_tanh,\n",
        "    \"relu\": activation_relu,\n",
        "    \"linear\": activation_linear\n",
        "}"
      ],
      "metadata": {
        "id": "ateaBvACcWLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivada de função de ativação\n",
        "\n",
        "def derivative_sigmoid(x):\n",
        "    sig = activation_sigmoid(x)\n",
        "    return sig * (1 - sig)\n",
        "\n",
        "def derivative_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "def derivative_relu(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def derivative_linear(x):\n",
        "    return 1\n",
        "\n",
        "derivatives = {\n",
        "    \"sigmoid\": derivative_sigmoid,\n",
        "    \"tanh\": derivative_tanh,\n",
        "    \"relu\": derivative_relu,\n",
        "    \"linear\": derivative_linear\n",
        "}"
      ],
      "metadata": {
        "id": "3J6h54sgemxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, bias, inputs, weights, activation):\n",
        "    self.bias = bias\n",
        "    self.inputs = inputs\n",
        "    self.weights = weights\n",
        "    self.activation_function = activation_functions[activation]\n",
        "\n",
        "    if len(inputs) != len(weights):\n",
        "      raise Exception(f'Inputs and weights array shall have the same length. Inputs length: {len(inputs)}, weights length: {len(weights)}')\n",
        "\n",
        "  def forward(self):\n",
        "    initial_result = self.bias + (self.inputs * self.weights)\n",
        "    result = self.activation_function(initial_result)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "ZYOJN3kVp1iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "  def __init__(self, type, bias, inputs, weights, activation, size):\n",
        "    self.type = type\n",
        "    self.bias = bias\n",
        "    self.inputs = inputs\n",
        "    self.weights = weights\n",
        "    self.activation = activation\n",
        "    self.size = size\n",
        "\n",
        "    self.perceptrons = [\n",
        "      Perceptron(\n",
        "        bias=self.bias[i],\n",
        "        inputs=self.inputs[i],\n",
        "        weights=self.weights[i],\n",
        "        activation=self.activation\n",
        "      ) for i in range(size)\n",
        "    ]\n",
        "\n",
        "  def forward(self):\n",
        "    layer_result = []\n",
        "\n",
        "    for perceptron in self.perceptrons:\n",
        "      perceptron_result = perceptron.forward()\n",
        "      layer_result.append(perceptron_result)\n",
        "\n",
        "    return layer_result"
      ],
      "metadata": {
        "id": "9DTWubFmCMaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self, n_classes, hidden_layer_sizes, activation, learning_rate):\n",
        "    self.hidden_layer_sizes = hidden_layer_sizes\n",
        "    self.activation = activation\n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "    self.weights = []\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    n_features = len(inputs)\n",
        "    layer_sizes = [n_features] + self.hidden_layer_sizes + [self.n_classes]\n",
        "\n",
        "    self.weights += [np.random.randn(n) for n in layer_sizes]\n",
        "    print(self.weights)\n",
        "\n",
        "    for layer in range(len(layer_sizes)):\n",
        "      n_perceptrons = layer_sizes[layer]\n",
        "      print(f'{n_perceptrons} for layer {layer + 1}')\n",
        "      for perceptron in range(n_perceptrons):\n",
        "        i = 0"
      ],
      "metadata": {
        "id": "MzflzeXLJtPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(hidden_layer_sizes=[2, 4, 2], activation=\"sigmoid\", learning_rate=0.1, n_classes=1)\n",
        "mlp.forward(X_classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0R41qdQq4V9",
        "outputId": "6aa0d53a-a4ee-4304-9bae-ff751a5a13c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 0.19686124,  0.73846658,  0.17136828, -0.11564828, -0.3011037 ,\n",
            "       -1.47852199, -0.71984421, -0.46063877,  1.05712223,  0.34361829,\n",
            "       -1.76304016,  0.32408397, -0.38508228, -0.676922  ,  0.61167629,\n",
            "        1.03099952,  0.93128012, -0.83921752, -0.30921238,  0.33126343,\n",
            "        0.97554513, -0.47917424, -0.18565898, -1.10633497, -1.19620662,\n",
            "        0.81252582,  1.35624003, -0.07201012,  1.0035329 ,  0.36163603]), array([-0.64511975,  0.36139561]), array([ 1.53803657, -0.03582604,  1.56464366, -2.6197451 ]), array([0.8219025 , 0.08704707]), array([-0.29900735])]\n",
            "30 for layer 1\n",
            "2 for layer 2\n",
            "4 for layer 3\n",
            "2 for layer 4\n",
            "1 for layer 5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WECeh57QhL9O"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}