{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardobizerra/custom-mlp/blob/main/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WECeh57QhL9O"
      },
      "source": [
        "## IF867 - Introdução à Aprendizagem Profunda\n",
        "### 1ª atividade prática\n",
        "\n",
        "Discente(s): Ricardo Bizerra de Lima Filho (rblf)\n",
        "\n",
        "Período: 2024.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRkbCshWhfya"
      },
      "source": [
        "## Instruções e Requisitos\n",
        "- Objetivo: Implementar e treinar um Multilayer Perceptron (MLP), inteiramente em [NumPy](https://numpy.org/doc/stable/) ou [Numba](https://numba.readthedocs.io/en/stable/index.html), sem o uso de bibliotecas de aprendizado profundo.\n",
        "- A atividade pode ser feita em dupla.\n",
        "\n",
        "### Tarefas\n",
        "\n",
        "__Implementação (50%):__\n",
        "\n",
        "- Construa um MLP com uma camada de entrada, pelo menos duas camadas ocultas e uma camada de saída.\n",
        "- Implemente pelo menos duas funções de ativação diferentes para as camadas ocultas; use Sigmoid e Linear para a camada de saída.\n",
        "- Implemente forward e backpropagation.\n",
        "- Implemente um otimizador de sua escolha, adequado ao problema abordado.\n",
        "- Implemente as funções de treinamento e avaliação.\n",
        "\n",
        "__Aplicação (30%):__\n",
        "\n",
        "  Teste se os seus modelos estão funcionando bem com as seguintes tarefas:\n",
        "  - Regressão\n",
        "  - Classificação binária\n",
        "\n",
        "__Experimentação (20%):__\n",
        "\n",
        "  Teste os seus modelos com variações na arquitetura, no pré-processamento, etc. Escolha pelo menos uma das seguintes opções:\n",
        "  - Variações na inicialização de pesos\n",
        "  - Variações na arquitetura\n",
        "  - Implementação de técnicas de regularização\n",
        "  - Visualização das ativações e gradientes\n",
        "\n",
        "***Bônus:*** Implemente o MLP utilizando uma biblioteca de machine learning (ex.: [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/?hl=pt-br), [tinygrad](https://docs.tinygrad.org/), [Jax](https://jax.readthedocs.io/en/latest/quickstart.html)) e teste-o em uma das aplicações e em um dos experimentos propostos. O bônus pode substituir um dos desafios de aplicação ou experimentos feitos em NumPy, ou simplesmente somar pontos para a pontuação geral.\n",
        "\n",
        "### Datasets recomendados:\n",
        "Aqui estão alguns datasets recomendados, mas fica a cargo do aluno escolher os datasets que utilizará na atividade, podendo escolher um dataset não listado abaixo.\n",
        "- Classificação\n",
        "\n",
        "  - [Iris](https://archive.ics.uci.edu/dataset/53/iris)\n",
        "  - [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
        "  - [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)\n",
        "\n",
        "- Regressão\n",
        "\n",
        "  - [Air Quality](https://archive.ics.uci.edu/dataset/360/air+quality)\n",
        "  - [Student Performance](https://archive.ics.uci.edu/dataset/320/student+performance)\n",
        "  - [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
        "\n",
        "### Requisitos para Entrega\n",
        "\n",
        "Um notebook Jupyter (de preferência, o link do colab) ou script Python contendo:\n",
        "\n",
        "- Código: Implementação completa da MLP.\n",
        "- Gráficos e Análises: Gráficos da curva de perda, ativações, gradientes e insights do treinamento, resultantes dos experimentos com parada antecipada e diferentes técnicas de regularização.\n",
        "- Relatório: Um breve relatório detalhando o impacto de várias configurações de hiperparâmetros(ex.: inicialização de pesos, número de camadas ocultas e neurônios) e métodos de regularização no desempenho do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__PXHTW_wYR",
        "outputId": "f00a9586-63bf-4ffe-a999-98ac8449a7ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bdV-R1nvADsf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "lFH3riTWq-J1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset para Classificação Binária: Breast Cancer Wisconsin\n",
        "\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "X_classification = breast_cancer_wisconsin_diagnostic.data.features.values\n",
        "\n",
        "y_classification = breast_cancer_wisconsin_diagnostic.data.targets.values\n",
        "y_classification = np.where(y_classification == 'B', 1, 0)"
      ],
      "metadata": {
        "id": "YWK3-qtO_zUN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset para Regressão: Student Performance\n",
        "\n",
        "student_performance = fetch_ucirepo(id=320)\n",
        "\n",
        "X_regression = student_performance.data.features.values\n",
        "\n",
        "remove_indexes = [8, 9, 10, 11]\n",
        "\n",
        "X_regression = np.delete(X_regression, remove_indexes, axis=1)\n",
        "\n",
        "def binary_map(value):\n",
        "  if value in ['GP', 'M', 'U', 'GT3', 'T', 'yes']: return 1\n",
        "  if value in ['MS', 'F', 'R', 'LE3', 'A', 'no' ]: return 0\n",
        "  return value\n",
        "\n",
        "X_regression = np.vectorize(binary_map)(X_regression)\n",
        "\n",
        "normalize_indexes = {\n",
        "  2: (15, 22),\n",
        "  6: (0, 4),\n",
        "  7: (0, 4),\n",
        "  8: (1, 4),\n",
        "  9: (1, 4),\n",
        "  10: (0, 4),\n",
        "  19: (1, 5),\n",
        "  20: (1, 5),\n",
        "  21: (1, 5),\n",
        "  22: (1, 5),\n",
        "  23: (1, 5),\n",
        "  24: (1, 5),\n",
        "  25: (0, 93),\n",
        "}\n",
        "\n",
        "def normalize_by_index(value, index):\n",
        "  if index in normalize_indexes:\n",
        "    min_val, max_val = normalize_indexes[index]\n",
        "    return (int(value) - min_val) / (max_val - min_val)\n",
        "  return value\n",
        "\n",
        "# Apply transformation\n",
        "X_regression = np.array([\n",
        "  [normalize_by_index(value, idx) for idx, value in enumerate(row)]\n",
        "  for row in X_regression\n",
        "])\n",
        "\n",
        "y_regression = student_performance.data.targets.values"
      ],
      "metadata": {
        "id": "czVfXbiXcUSf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções de ativação\n",
        "\n",
        "def activation_sigmoid(x):\n",
        "  x = np.clip(x, -500, 500)\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def activation_tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def activation_relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def activation_linear(x):\n",
        "  return x\n",
        "\n",
        "activation_functions = {\n",
        "    \"sigmoid\": activation_sigmoid,\n",
        "    \"tanh\": activation_tanh,\n",
        "    \"relu\": activation_relu,\n",
        "    \"linear\": activation_linear\n",
        "}"
      ],
      "metadata": {
        "id": "ateaBvACcWLV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivada de função de ativação\n",
        "\n",
        "def derivative_sigmoid(x):\n",
        "    sig = activation_sigmoid(x)\n",
        "    return sig * (1 - sig)\n",
        "\n",
        "def derivative_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "def derivative_relu(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def derivative_linear(x):\n",
        "    return 1\n",
        "\n",
        "derivatives = {\n",
        "    \"sigmoid\": derivative_sigmoid,\n",
        "    \"tanh\": derivative_tanh,\n",
        "    \"relu\": derivative_relu,\n",
        "    \"linear\": derivative_linear\n",
        "}"
      ],
      "metadata": {
        "id": "3J6h54sgemxV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "  def __init__(self, n_classes, hidden_layer_sizes, activation, learning_rate):\n",
        "    self.hidden_layer_sizes = hidden_layer_sizes\n",
        "    self.activation = activation_functions[activation]\n",
        "    self.activation_derivative = derivatives[activation]\n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_classes = n_classes\n",
        "\n",
        "    self.weights = []\n",
        "    self.bias = []\n",
        "    self.inputs = []\n",
        "    self.outputs = []\n",
        "    self.pre_outputs = []\n",
        "    self.error = []\n",
        "    self.error_derivative = []\n",
        "\n",
        "    self.layer_sizes = []\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.inputs = inputs\n",
        "\n",
        "    n_features = len(self.inputs[0])\n",
        "    self.layer_sizes = [n_features] + self.hidden_layer_sizes + [self.n_classes]\n",
        "\n",
        "    if not self.weights:\n",
        "      self.weights = [np.random.randn(self.layer_sizes[layer], self.layer_sizes[layer + 1]) for layer in range(len(self.layer_sizes) - 1)]\n",
        "      self.bias = [np.random.randn(1, self.layer_sizes[layer + 1]) for layer in range(len(self.layer_sizes) - 1)]\n",
        "\n",
        "    outputs = [self.inputs]\n",
        "    pre_outputs = []\n",
        "\n",
        "    for layer in range(len(self.weights)):\n",
        "      z = np.dot(outputs[-1], self.weights[layer]) + self.bias[layer]\n",
        "      pre_outputs.append(z)\n",
        "      a = self.activation(z)\n",
        "      outputs.append(a)\n",
        "\n",
        "    self.outputs = outputs\n",
        "    self.pre_outputs = pre_outputs\n",
        "\n",
        "  def get_error(self, X, y):\n",
        "    self.forward(X)\n",
        "    self.error = 0.5 * np.square(self.outputs[-1] - y)\n",
        "    self.error_derivative = np.array(self.outputs[-1] - y)\n",
        "\n",
        "  def backward(self):\n",
        "    batch_size = len(self.inputs)\n",
        "    delta = self.error_derivative * self.activation_derivative(self.pre_outputs[-1])\n",
        "\n",
        "    for layer in range(len(self.layer_sizes) - 2, -1, -1):\n",
        "      calculated_output = self.outputs[layer]\n",
        "      weight_update = np.dot(calculated_output.T, delta) / batch_size\n",
        "      bias_update = np.mean(delta, axis=0, keepdims=True)\n",
        "\n",
        "      self.weights[layer] -= self.learning_rate * weight_update\n",
        "      self.bias[layer] -= self.learning_rate * bias_update\n",
        "\n",
        "      if layer > 0:\n",
        "        delta = np.dot(delta, self.weights[layer].T) * self.activation_derivative(self.pre_outputs[layer - 1])"
      ],
      "metadata": {
        "id": "MzflzeXLJtPb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = y_classification.shape[1]\n",
        "\n",
        "mlp = MLP(hidden_layer_sizes=[20, 10, 20, 10], activation=\"sigmoid\", learning_rate=0.1, n_classes=n_classes)\n",
        "mlp.get_error(X_classification, y_classification)\n",
        "mlp.backward()"
      ],
      "metadata": {
        "id": "l0R41qdQq4V9"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WECeh57QhL9O"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}